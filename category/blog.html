<!DOCTYPE html>
<html lang="en">
        <head>
                        <meta charset="utf-8" />
                        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
                        <meta name="generator" content="Pelican" />
                        <title>Jamie's Blog - Blog</title>
                        <link rel="stylesheet" href="../theme/css/main.css" />
                                <link href="https://blog.changs.co.uk/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Jamie's Blog Atom Feed" />
                        <!-- Cloudflare Web Analytics --><script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "0358c4be608641c1ad90cd87801da29b"}'></script><!-- End Cloudflare Web Analytics -->
        </head>

        <body id="index" class="home">
                <header id="banner" class="body">
                        <h1><a href="../">Jamie's Blog</a></h1>
                        <nav><ul>
                                                <li class="active"><a href="../category/blog.html">Blog</a></li>
                        </ul></nav>
                </header><!-- /#banner -->

                <aside id="featured" class="body">
                    <article>
                        <h1 class="entry-title"><a href="../asyncio-backpressure-follow-up.html">Asyncio backpressure - follow up</a></h1>
<footer class="post-info">
        <abbr class="published" title="2025-09-14T00:00:00+01:00">
                Published: Sun 14 September 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info --><p>Previously when discussing <a href="../asyncio-backpressure-processing-lots-of-tasks-in-parallel.html">asyncio backpressure</a> I've made some claims that were not necessarily complete.</p>
<p>I said:</p>
<blockquote>
<p>It works well for 100s of urls but when we hit a big number like 10000s we have a problem.</p>
<p>The program seemingly hangs. This is because all the tasks are being created first and only then to do allow the tasks to start executing. The program will also use much more memory than it needs and generally might slow down due to more context switching. Definitely not what we want</p>
</blockquote>
<p>There are 2 issues here:</p>
<ul>
<li>First about the program hanging, it's actually quite hard to observe that behaviour. </li>
<li>Second about the numbers, 10000s of tasks is actually not a big number for asyncio.</li>
</ul>
<p>This was pointed out in a <a href="https://github.com/Jamie-Chang/aiointerpreters/issues/3">Github issue</a> by <a href="https://github.com/bmwant">Misha Behersky</a>. Additionally I had not made it very clear why I proposed using semaphore like:</p>
<div class="highlight"><pre><span></span><code><span class="k">async</span> <span class="k">def</span> <span class="nf">process_all</span><span class="p">(</span><span class="n">urls</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">semaphore</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Semaphore</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">TaskGroup</span><span class="p">()</span> <span class="k">as</span> <span class="n">tg</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">await</span> <span class="n">semaphore</span><span class="o">.</span><span class="n">acquire</span><span class="p">()</span>
            <span class="n">tg</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span><span class="n">process_one</span><span class="p">(</span><span class="n">url</span><span class="p">))</span><span class="o">.</span><span class="n">add_done_callback</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">semaphore</span><span class="o">.</span><span class="n">release</span><span class="p">())</span>
</code></pre></div>

<p>As opposed to using it in a more standard way:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">process_one</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">semaphore</span><span class="p">):</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">semaphore</span><span class="p">:</span>
        <span class="o">...</span>
</code></pre></div>

<p>In order to properly explain the behaviour, I needed to construct a much better example so that I can benchmark both memory and speed.</p>
<h2>Simulation</h2>
<p>First and foremost, I've been testing back pressure by making concurrent calls to fetch wikipedia articles. </p>
<div class="highlight"><pre><span></span><code><span class="k">async</span> <span class="k">def</span> <span class="nf">request</span><span class="p">(</span><span class="n">client</span><span class="p">:</span> <span class="n">httpx</span><span class="o">.</span><span class="n">AsyncClient</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">await</span> <span class="n">client</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="o">...</span>
</code></pre></div>

<p>This is a good real world test, but when we are experimenting with thousands of concurrent calls, it adds load to unsuspecting servers. </p>
<p>I could set up my own servers, but we have a simpler choice.</p>
<p>One of the benefits of asyncio is that it provides primitives for concurrent operations. We can in that case easily simulate the network latency using <code>asyncio.sleep</code>:</p>
<div class="highlight"><pre><span></span><code><span class="k">async</span> <span class="k">def</span> <span class="nf">request</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">))</span>  <span class="c1"># simulate the time delay for getting requests</span>
</code></pre></div>

<p>Here we assume the latency is between 100 and 200 ms. But we can also extend this to match a distribution observe in the real world. Similarly we can use this to simulate load with databases and message queues.</p>
<h2>Measuring the speed and memory</h2>
<p>Testing the speed or duration is simple, the best way is using <a href="https://docs.python.org/3/library/time.html#time.perf_counter">time.perf_counter</a>. We can compose this into a context manager like this:</p>
<div class="highlight"><pre><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span> <span class="nf">timer</span><span class="p">(</span><span class="n">message</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="kc">None</span><span class="p">]:</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="s2">&quot;s&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Similarly we can track the peak memory used by using <a href="https://docs.python.org/3/library/tracemalloc.html">tracemalloc</a>:</p>
<div class="highlight"><pre><span></span><code><span class="nd">@contextmanager</span>
<span class="k">def</span> <span class="nf">memory_profiler</span><span class="p">(</span><span class="n">message</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="kc">None</span><span class="p">]:</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">peak_memory</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">get_traced_memory</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak memory usage: </span><span class="si">{</span><span class="n">peak_memory</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> bytes&quot;</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">tracemalloc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</code></pre></div>

<h2>Testing different implementations</h2>
<p>In the original article, I proposed both batching and semaphore as methods of back pressure. So our test scenarios are as follows </p>
<ol>
<li>batched execution.</li>
<li>acquiring semaphore inside the task as Python intended.</li>
<li>acquiring semaphore before task creation and releasing with callback as I proposed.</li>
</ol>
<p>Finally a bonus implementation suggested in the issue thread to release the semaphore at the end of the function call:</p>
<div class="highlight"><pre><span></span><code><span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">semaphore</span> <span class="o">=</span> <span class="n">Semaphore</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">with</span> <span class="n">TaskGroup</span><span class="p">()</span> <span class="k">as</span> <span class="n">tg</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">await</span> <span class="n">semaphore</span><span class="o">.</span><span class="n">acquire</span><span class="p">()</span>
            <span class="n">tg</span><span class="o">.</span><span class="n">create_task</span><span class="p">(</span><span class="n">process</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">semaphore</span><span class="p">))</span>


<span class="k">async</span> <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">semaphore</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="o">...</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">semaphore</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
</code></pre></div>

<p>The code can be found <a href="https://github.com/Jamie-Chang/concurreny-bench">here</a>. We run 100,000 inputs for each implementation limiting concurrency to 500 at a time.</p>
<h2>Results</h2>
<table>
<thead>
<tr>
<th>File</th>
<th>Description</th>
<th>Memory usage in bytes</th>
<th>Duration in seconds</th>
</tr>
</thead>
<tbody>
<tr>
<td>batching.py</td>
<td>Using batched to process things in batches as opposed to using semaphores</td>
<td>821,692</td>
<td>41.7</td>
</tr>
<tr>
<td>semaphore1.py</td>
<td>Traditional pythonic way of using semaphore, does not limit task creation</td>
<td>152,154,848</td>
<td>30.9</td>
</tr>
<tr>
<td>semaphore2.py</td>
<td>Semaphore limiting task creation with callback</td>
<td>1,018,796</td>
<td>30.2</td>
</tr>
<tr>
<td>semaphore3.py</td>
<td>Semaphore limiting task creation with release called in the task function</td>
<td>839,176</td>
<td>30.2</td>
</tr>
</tbody>
</table>
<h2>Analysis</h2>
<p>Traditional use of semaphore does not limit the number of tasks being created, we must first create all 100,000 tasks and then start processing the tasks. As a result, the amount of memory requires is many times higher. Though the difference in speed is fairly small, it is consistently observable as we are not able to start processing during the creation phase.</p>
<p>Another interesting result is that the semaphore2 with the callback uses more memory than just passing the semaphore to release in semaphore3. This is a quirk of constructing an extra lambda as a callback. Additionally, it may be more obvious than using the callback, so this method is definitely worth considering.</p>
<p>Finally I want to talk about batching. Batching is very memory efficient as it doesn't need any extra objects however it does take a lot longer.
This is explained in my original post:</p>
<blockquote>
<p>The problem is if we have a small amount of tasks with long wait times then it'll slow down the whole batch.</p>
</blockquote>
<p>Notice that our distributions has a lot of variance:</p>
<div class="highlight"><pre><span></span><code><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
</code></pre></div>

<p>if we reduce this to <code>random.uniform(0.1, 0.11)</code> we have closer results</p>
<table>
<thead>
<tr>
<th>File</th>
<th>Duration in seconds</th>
</tr>
</thead>
<tbody>
<tr>
<td>batching.py</td>
<td>24.65</td>
</tr>
<tr>
<td>semaphore1.py</td>
<td>22.0</td>
</tr>
<tr>
<td>semaphore2.py</td>
<td>21.1</td>
</tr>
<tr>
<td>semaphore3.py</td>
<td>21.1</td>
</tr>
</tbody>
</table>
<p>My view is batching and the 2 semaphore solutions are all very good solutions. Batching is simple, but you can get more performance out of using semaphores just not in the obvious way.</p>
<p>On the other hand using semaphore normally is good but you should be aware of the memory implication.</p>
<h2>Finally</h2>
<p>I've spent a lot of time investigating asyncio back pressure here. The point is to provide the full context of the different options to use. </p>
<p>I also hope that I've provided some ideas around how you might investigate different design patterns yourself.</p>                    </article>
                </aside><!-- /#featured -->
                    <section id="content" class="body">
                        <h1>Other articles</h1>
                        <hr />
                        <ol id="posts-list" class="hfeed">

                <li><article class="hentry">
                    <header>
                        <h1><a href="../simplify-lambda-deployments-with-uv.html" rel="bookmark"
                               title="Permalink to Simplify lambda deployments with UV">Simplify lambda deployments with UV</a></h1>
                    </header>

                    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-09-01T00:00:00+01:00">
                Published: Mon 01 September 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info -->                        <p>The python packaging landscape and developer experience has shifted dramatically in the past year or so with <a href="https://docs.astral.sh/uv/">uv</a>'s launch marked a pivotal moment. But behind the scenes many PEPs have worked to get us to this point. </p>
<p>One such PEP was <a href="https://peps.python.org/pep-0723/">PEP 723 – Inline script metadata</a> which we discussed …</p>
                        <a class="readmore" href="../simplify-lambda-deployments-with-uv.html">read more</a>
                    </div><!-- /.entry-content -->
                </article></li>

                <li><article class="hentry">
                    <header>
                        <h1><a href="../dynamic-config-part-1-pydantic-and-file-watchers.html" rel="bookmark"
                               title="Permalink to Dynamic config part 1: Pydantic and file watchers">Dynamic config part 1: Pydantic and file watchers</a></h1>
                    </header>

                    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-08-26T00:00:00+01:00">
                Published: Tue 26 August 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info -->                        <p>Feature flags or dynamic configuration is something that I find very useful, however I've never had the chance to use them. This is for a lack of options <a href="https://launchdarkly.com/">launchdarkly</a>, <a href="https://www.flagsmith.com/">flagsmith</a> and <a href="https://www.getunleash.io/">unleash</a> to name a few. </p>
<p>SaaS options can be amazing with a full array of features, but I would …</p>
                        <a class="readmore" href="../dynamic-config-part-1-pydantic-and-file-watchers.html">read more</a>
                    </div><!-- /.entry-content -->
                </article></li>

                <li><article class="hentry">
                    <header>
                        <h1><a href="../subinterpreters-and-asyncio.html" rel="bookmark"
                               title="Permalink to Subinterpreters and Asyncio">Subinterpreters and Asyncio</a></h1>
                    </header>

                    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-08-05T00:00:00+01:00">
                Published: Tue 05 August 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info -->                        <p><a href="https://peps.python.org/pep-0734">PEP-734</a> subinterpreters in the stdlib has officially been included in the Python 3.14 as a very late <a href="https://docs.python.org/3.14/whatsnew/3.14.html#whatsnew314-pep734">addition</a>. subinterpreters now has a new home in the standard library module called <a href="https://docs.python.org/3.14/library/concurrent.interpreters.html">concurrent.interpreters</a>.</p>
<p>If you've been following my blog posts you'll know that I'm particularly excited about this feature. </p>
<ul>
<li><a href="../how-good-are-sub-interpreters-in-python-now.html">How …</a></li></ul>
                        <a class="readmore" href="../subinterpreters-and-asyncio.html">read more</a>
                    </div><!-- /.entry-content -->
                </article></li>

                <li><article class="hentry">
                    <header>
                        <h1><a href="../python-314-3-smaller-features.html" rel="bookmark"
                               title="Permalink to Python 3.14: 3 smaller features">Python 3.14: 3 smaller features</a></h1>
                    </header>

                    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-07-11T00:00:00+01:00">
                Published: Fri 11 July 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info -->                        <p>Python 3.14 is just around the corner and it's jampacked with huge updates:</p>
<ul>
<li><a href="../python-314-state-of-free-threading.html">Free threading and multiple interpreters?</a></li>
<li><a href="../t-strings-the-good-and-the-ugly.html">Template strings</a></li>
</ul>
<p>But as with any release, there are many nice smaller and less noticeable features. Features you won't see unless you comb through the entire <a href="https://docs.python.org/3.14/whatsnew/3.14.html">release notes</a>. Luckily I am …</p>
                        <a class="readmore" href="../python-314-3-smaller-features.html">read more</a>
                    </div><!-- /.entry-content -->
                </article></li>

                <li><article class="hentry">
                    <header>
                        <h1><a href="../my-chinese-birthdays-time-keeping-is-hard.html" rel="bookmark"
                               title="Permalink to My Chinese birthdays, time keeping is hard!">My Chinese birthdays, time keeping is hard!</a></h1>
                    </header>

                    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-06-25T00:00:00+01:00">
                Published: Wed 25 June 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info -->                        <p>I grew up in both the UK and China. So I'd like to think I have a little understanding of both cultures. China uses both the western gregorian calendar and a version of lunar calendar called 农历. This means I have a Chinese lunar birthday as well as a …</p>
                        <a class="readmore" href="../my-chinese-birthdays-time-keeping-is-hard.html">read more</a>
                    </div><!-- /.entry-content -->
                </article></li>

                <li><article class="hentry">
                    <header>
                        <h1><a href="../asyncio-backpressure-processing-lots-of-tasks-in-parallel.html" rel="bookmark"
                               title="Permalink to Asyncio backpressure - Processing lots of tasks in parallel">Asyncio backpressure - Processing lots of tasks in parallel</a></h1>
                    </header>

                    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-06-20T00:00:00+01:00">
                Published: Fri 20 June 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info -->                        <p>There's mixed feedback to Asyncio in the community. Some people passionately hate it whilst others believe "writing async make program go fast". This debate is way too much for me to cover here right now. Though maybe I'll look at it in the future. </p>
<p>For me I use asyncio a …</p>
                        <a class="readmore" href="../asyncio-backpressure-processing-lots-of-tasks-in-parallel.html">read more</a>
                    </div><!-- /.entry-content -->
                </article></li>

                <li><article class="hentry">
                    <header>
                        <h1><a href="../dockers-mcp-toolkit-first-look.html" rel="bookmark"
                               title="Permalink to Docker's MCP toolkit First Look">Docker's MCP toolkit First Look</a></h1>
                    </header>

                    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-06-12T00:00:00+01:00">
                Published: Thu 12 June 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info -->                        <p>Short update since <a href="../first-look-at-mcp.html">First Look at MCP</a>. Docker has released it's <a href="https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/">MCP toolkit</a> which includes a catalog of MCP servers as well as helpers to connect to the MCP clients.</p>
<p>It is exceeding easy to use it, docker is registered as a single MCP server for your client. And tools …</p>
                        <a class="readmore" href="../dockers-mcp-toolkit-first-look.html">read more</a>
                    </div><!-- /.entry-content -->
                </article></li>

                <li><article class="hentry">
                    <header>
                        <h1><a href="../first-look-at-mcp.html" rel="bookmark"
                               title="Permalink to First Look at MCP">First Look at MCP</a></h1>
                    </header>

                    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-06-03T00:00:00+01:00">
                Published: Tue 03 June 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info -->                        <p>Previously I've played with tool calling in <a href="../python-in-python-sandboxing-llm-generated-code.html">Langchain and Python sandboxes</a>. But recently MCP (Model Context Protocol) is front and center. So I tried to create my own github MCP in Python to integrate <a href="https://www.cursor.com/">cursor</a> with the github cli.</p>
<h1>What is MCP?</h1>
<p>Before we get started, its good to familiarise …</p>
                        <a class="readmore" href="../first-look-at-mcp.html">read more</a>
                    </div><!-- /.entry-content -->
                </article></li>

                <li><article class="hentry">
                    <header>
                        <h1><a href="../python-314-state-of-free-threading.html" rel="bookmark"
                               title="Permalink to Python 3.14: State of free threading">Python 3.14: State of free threading</a></h1>
                    </header>

                    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-05-26T00:00:00+01:00">
                Published: Mon 26 May 2025
        </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="../author/jamie-chang.html">Jamie Chang</a>
                </address>
        <p>In <a href="../category/blog.html">Blog</a>.</p>
        
</footer><!-- /.post-info -->                        <p>In my posts earlier this year I talked about the parallelism performance on 3.13 free-threaded builds. In particular I looked at solving an advent of code <a href="https://adventofcode.com/2024/day/6">problem</a>. In <a href="../how-free-are-threads-in-python-now.html">How free are threads in Python now?</a> I discovered significant performance penalties for using free-threading and a lack of tooling available …</p>
                        <a class="readmore" href="../python-314-state-of-free-threading.html">read more</a>
                    </div><!-- /.entry-content -->
                </article></li>
                    </ol><!-- /#posts-list -->
  <nav>
    <ul>
      <li>Page 1 / 3</li>
        <li><a href="../category/blog2.html">&rang;</a></li>
        <li><a href="../category/blog3.html">&Rang;</a></li>
    </ul>
  </nav>
                    </section><!-- /#content -->
                <section id="extras" class="body">
                                <div class="social">
                                        <h2>social</h2>
                                        <ul>
                                                        <li><a href="https://blog.changs.co.uk/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                                                        <li><a href="https://github.com/Jamie-Chang/">Github</a></li>
                                                        <li><a href="https://www.linkedin.com/in/jamie-chang-4423ba125/">LinkedIn</a></li>
                                                        <li><a href="https://bsky.app/profile/jamie-chang.bsky.social/">Bluesky</a></li>
                                        </ul>
                                </div><!-- /.social -->
                </section><!-- /#extras -->

                <footer id="contentinfo" class="body">
                        <address id="about" class="vcard body">
                                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                        </address><!-- /#about -->

                        <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
                </footer><!-- /#contentinfo -->

        </body>
</html>